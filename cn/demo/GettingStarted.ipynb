{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this GettingStarted article, we will build a robot for answering questions in IQ test with the help of [DeepLearning.scala](http://deeplearning.thoughtworks.school/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we are building a robot for answering questions in IQ test like this:\n",
    "\n",
    "> What is the next number in sequence:\n",
    ">> 3, 6, 9, ?\n",
    ">\n",
    "> The answer is 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepared some questions and corresponding answers as [INDArray](https://oss.sonatype.org/service/local/repositories/public/archive/org/nd4j/nd4j-api/0.8.0/nd4j-api-0.8.0-javadoc.jar/!/org/nd4j/linalg/api/ndarray/INDArray.html)s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ndarray.INDArray\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mTrainingQuestions\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mnd4j\u001b[39m.\u001b[32mlinalg\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mndarray\u001b[39m.\u001b[32mINDArray\u001b[39m = [[0.00, 1.00, 2.00],\n",
       " [4.00, 7.00, 10.00],\n",
       " [13.00, 15.00, 17.00]]\n",
       "\u001b[36mExpectedAnswers\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mnd4j\u001b[39m.\u001b[32mlinalg\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mndarray\u001b[39m.\u001b[32mINDArray\u001b[39m = [3.00, 13.00, 19.00]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.nd4j::nd4s:0.8.0`\n",
    "import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "\n",
    "val TrainingQuestions: INDArray = {\n",
    "  import org.nd4s.Implicits._\n",
    "  Array(\n",
    "    Array(0, 1, 2),\n",
    "    Array(4, 7, 10),\n",
    "    Array(13, 15, 17)\n",
    "  ).toNDArray\n",
    "}\n",
    "\n",
    "val ExpectedAnswers: INDArray = {\n",
    "  import org.nd4s.Implicits._\n",
    "  Array(\n",
    "    Array(3),\n",
    "    Array(13),\n",
    "    Array(19)\n",
    "  ).toNDArray\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These samples will be used to train the robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this article, we will build the robot in the following steps:\n",
    "\n",
    "1. Install DeepLearning.scala, which is the framework that helps us build the robot.\n",
    "1. Setup configuration (also known as hyperparameters) of the robot.\n",
    "1. Build an untrained neural network of the robot.\n",
    "1. Train the neural network using the above samples.\n",
    "1. Test the robot seeing if the robot have been learnt how to answer these kind of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DeepLearning.scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepLearning.scala is hosted on Maven Central repository.\n",
    "\n",
    "You can use magic imports in [jupyter-scala](https://github.com/alexarchambault/jupyter-scala) or [Ammonite-REPL](http://www.lihaoyi.com/Ammonite/#Ammonite-REPL) to download DeepLearning.scala and its dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                      \u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.thoughtworks.deeplearning::plugins-builtins:2.0.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use [sbt](http://www.scala-sbt.org), please add the following settings into your `build.sbt`:\n",
    "\n",
    "``` scala\n",
    "// All DeepLearning.scala built-in plugins.\n",
    "libraryDependencies += \"com.thoughtworks.deeplearning\" %% \"plugins-builtins\" % \"latest.release\"\n",
    "\n",
    "// The native backend for nd4j.\n",
    "libraryDependencies += \"org.nd4j\" % \"nd4j-native-platform\" % \"0.8.0\"\n",
    "\n",
    "// Uncomment the following line to switch to the CUDA backend for nd4j.\n",
    "// libraryDependencies += \"org.nd4j\" % \"nd4j-cuda-8.0-platform\" % \"0.8.0\"\n",
    "\n",
    "// The magic import compiler plugin, which may be used to import DeepLearning.scala distributed in source format.\n",
    "addCompilerPlugin(\"com.thoughtworks.import\" %% \"import\" % \"latest.release\")\n",
    "\n",
    "// The ThoughtWorks Each library, which provides the `monadic`/`each` syntax.\n",
    "libraryDependencies += \"com.thoughtworks.each\" %% \"each\" % \"latest.release\"\n",
    "addCompilerPlugin(\"org.scalamacros\" % \"paradise\" % \"2.1.0\" cross CrossVersion.full)\n",
    "\n",
    "fork := true\n",
    "\n",
    "scalaVersion := \"2.11.11\"\n",
    "```\n",
    "\n",
    "Note that this example must run on Scala 2.11.11 because [nd4s](http://nd4j.org/scala) does not support Scala 2.12. Make sure there is not a setting like `scalaVersion := \"2.12.x\"` in your `build.sbt`.\n",
    "\n",
    "See [Scaladex](https://index.scala-lang.org/thoughtworksinc/deeplearning.scala) to install DeepLearning.scala in other build tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters are global configurations for a neural network.\n",
    "\n",
    "For this robot, we want to set its learning rate, which determines how fast the robot change its inner weights.\n",
    "\n",
    "In DeepLearning.scala, hyperparameters can be introduced by plugins, which is a small piece of code loaded from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interp.load(scala.io.Source.fromURL(new java.net.URL(\"https://gist.github.com/Atry/1fb0608c655e3233e68b27ba99515f16/raw/39ba06ee597839d618f2fcfe9526744c60f2f70a/FixedLearningRate.sc\")).mkString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By loading the hyperparameter plugin `FixedLearningRate`, we are able to create the context of neural network with `learningRate` parameter.\n",
    "\n",
    "See `FixedLearningRate`'s [README](https://gist.github.com/Atry/1fb0608c655e3233e68b27ba99515f16#file-readme-ipynb) for instructions for sbt projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins.Builtins\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.thoughtworks.deeplearning.plugins.Builtins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All DeepLearning.scala built-in features are also provided by [plugins](http://deeplearning.thoughtworks.school/plugins). [Builtins](https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/plugins/Builtins.html) is the plugin that contains all other DeepLearning.scala built-in plugins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the context and setup learning rate to `0.003`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// `interp.load` is a workaround for https://github.com/lihaoyi/Ammonite/issues/649 and https://github.com/scala/bug/issues/10390\n",
    "interp.load(\"\"\"\n",
    "  import scala.concurrent.ExecutionContext.Implicits.global\n",
    "  import com.thoughtworks.feature.Factory\n",
    "  val hyperparameters = Factory[Builtins with FixedLearningRate].newInstance(learningRate = 0.003)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Factory](https://javadoc.io/page/com.thoughtworks.feature/factory_2.11/latest/com/thoughtworks/feature/Factory.html) if you are wondering how those plugins are composed together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Builtins` plugin contains some implicit values and views, which should be imported as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.implicits._\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an untrained neural network of the robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DeepLearning.scala, a neural network is simply a function that references some **weights**, which are mutable variables being changed automatically according to some goals during training.\n",
    "\n",
    "For example, given `x0`, `x1` and `x2` are the input sequence passed to the robot, we can build a function that returns the answer as `robotWeight0 * x0 + robotWeight1 * x1 + robotWeight2 * x2`, by adjusting those weights during training, the result should become close to the expected answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DeepLearning.scala, weights can be created as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36minitialValueOfRobotWeight\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayWeight\n",
       "\u001b[39m\n",
       "\u001b[36mrobotWeight\u001b[39m: \u001b[32mObject\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mINDArrayWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m with \u001b[32mhyperparameters\u001b[39m.\u001b[32mWeightApi\u001b[39m = Weight[fullName=$sess.cmd8Wrapper.Helper.robotWeight]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialValueOfRobotWeight: INDArray = {\n",
    "  import org.nd4j.linalg.factory.Nd4j\n",
    "  import org.nd4s.Implicits._\n",
    "  Nd4j.randn(3, 1)\n",
    "}\n",
    "\n",
    "import hyperparameters.INDArrayWeight\n",
    "val robotWeight = INDArrayWeight(initialValueOfRobotWeight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, `robotWeight` is a weight of n-dimensional array, say, [INDArrayWeight], initialized from random values. Therefore, the formula `robotWeight0 * x0 + robotWeight1 * x1 + robotWeight2 * x2` can be equivalent to a matrix multipication, written as a `dot` method call:\n",
    "\n",
    "[INDArrayWeight]: https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/plugins/INDArrayWeights$INDArrayWeight.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayLayer\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36miqTestRobot\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayLayer\n",
    "def iqTestRobot(questions: INDArray): INDArrayLayer = {\n",
    "  questions dot robotWeight\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `dot` method is a differentiable function provided by DeepLearning.scala.\n",
    "You can find other [n-dimensional array differentiable methods in Scaladoc](https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/plugins/INDArrayLayers$ImplicitsApi$INDArrayLayerOps.html)\n",
    "\n",
    "Unlike the functions in nd4s, all those differentiable functions accepts either an `INDArray`, `INDArrayWeight` \n",
    "or [INDArrayLayer], and returns one [Layer] of neural network, which can be composed into another differentiable function call.\n",
    "\n",
    "[INDArrayLayer]: https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/plugins/INDArrayLayers$INDArrayLayer.html\n",
    "\n",
    "[Layer]: https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/plugins/Layers$Layer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In DeepLearning.scala, when we train a neural network, our goal should always be minimizing the return value.\n",
    "\n",
    "For example, if `iqTestRobot(TrainingQuestions).train` get called repeatedly,\n",
    "the neural network would try to minimize `input dot robotWeight`.\n",
    "`robotWeight` would become smaller and smaller in order to make `input dot robotWeight` smaller,\n",
    "and `iqTestRobot(TrainingQuestions).predict` would return an `INDArray` of small numbers.\n",
    "\n",
    "What if you expect `iqTestRobot(TrainingQuestions).predict` to return `ExpectedAnswers`?\n",
    "\n",
    "You can create another neural network that evaluates how far between the result of `myNeuralNetwork` and your expectation. The new neural network is usually called **loss function**.\n",
    "\n",
    "In this article we will use square loss as the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.DoubleLayer\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msquareLoss\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.DoubleLayer\n",
    "def squareLoss(questions: INDArray, expectAnswer: INDArray): DoubleLayer = {\n",
    "  val difference = iqTestRobot(questions) - expectAnswer\n",
    "  (difference * difference).mean\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the `lossFunction` get trained continuously, its return value will be close to zero, and the result of  `myNeuralNetwork` must be close to the expected result at the same time.\n",
    "\n",
    "Note the `lossFunction` accepts a `questions` and `expectAnswer` as its parameter.\n",
    "The first parameter is the input data used to train the neural network, and the second array is the expected output.\n",
    "\n",
    "The `squareLoss` function itself is a neural network, internally using the layer returned by `iqTestRobot` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, there is a [train] method for `DoubleLayer`. It is a [ThoughtWorks Future] that performs one iteration of training.\n",
    "\n",
    "Since we want to repeatedly train the neural network of the robot, we need to create another `Future` that performs many iterations of training.\n",
    "\n",
    "In this article, we use [ThoughtWorks Each] to build such a `Future`:\n",
    "\n",
    "[train]: https://javadoc.io/page/com.thoughtworks.deeplearning/plugins-builtins_2.11/latest/com/thoughtworks/deeplearning/DeepLearning$$Ops.html#train(implicitmonoid:spire.algebra.MultiplicativeMonoid[Ops.this.typeClassInstance.Delta]):com.thoughtworks.future.Future[Ops.this.typeClassInstance.Data]\n",
    "\n",
    "[ThoughtWorks Future]: https://github.com/ThoughtWorksInc/future.scala\n",
    "\n",
    "[ThoughtWorks Each]: https://github.com/ThoughtWorksInc/each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$plugin.$                                            \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.each.Monadic._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.Await\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.duration.Duration\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.std.stream._\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $plugin.$ivy.`org.scalamacros:paradise_2.11.11:2.1.0`\n",
    "\n",
    "import com.thoughtworks.each.Monadic._\n",
    "import com.thoughtworks.future._\n",
    "import scala.concurrent.Await\n",
    "import scala.concurrent.duration.Duration\n",
    "import scalaz.std.stream._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mTotalIterations\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m500\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrain\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val TotalIterations = 500\n",
    "\n",
    "@monadic[Future]\n",
    "def train: Future[Stream[Double]] = {\n",
    "  for (iteration <- (0 until TotalIterations).toStream) yield {\n",
    "    squareLoss(TrainingQuestions, ExpectedAnswers).train.each\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can run the task to train the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlossByTime\u001b[39m: \u001b[32mStream\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mStream\u001b[39m(\n",
       "  \u001b[32m46.446085611979164\u001b[39m,\n",
       "  \u001b[32m25.62597147623698\u001b[39m,\n",
       "  \u001b[32m15.60748036702474\u001b[39m,\n",
       "  \u001b[32m10.731187184651693\u001b[39m,\n",
       "  \u001b[32m8.304683685302734\u001b[39m,\n",
       "  \u001b[32m7.047036488850911\u001b[39m,\n",
       "  \u001b[32m6.34877077738444\u001b[39m,\n",
       "  \u001b[32m5.919837951660156\u001b[39m,\n",
       "  \u001b[32m5.622165044148763\u001b[39m,\n",
       "  \u001b[32m5.389952341715495\u001b[39m,\n",
       "  \u001b[32m5.191807111104329\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lossByTime: Stream[Double] = Await.result(train.toScalaFuture, Duration.Inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a plot to show how the loss changed during iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <script type=\"text/javascript\">\n",
       "        require.config({\n",
       "  paths: {\n",
       "    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min',\n",
       "    plotly: 'https://cdn.plot.ly/plotly-1.12.0.min'\n",
       "  },\n",
       "\n",
       "  shim: {\n",
       "    plotly: {\n",
       "      deps: ['d3', 'jquery'],\n",
       "      exports: 'plotly'\n",
       "    }\n",
       "  }\n",
       "});\n",
       "        \n",
       "\n",
       "        require(['plotly'], function(Plotly) {\n",
       "          window.Plotly = Plotly;\n",
       "        });\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                             \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.element._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.layout._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.JupyterScala._\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.plotly-scala::plotly-jupyter-scala:0.3.2`\n",
    "\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.JupyterScala._\n",
    "\n",
    "plotly.JupyterScala.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"chart\" id=\"plot-1447757220\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "requirejs([\"plotly\"], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0],\"y\":[46.446085611979164,25.62597147623698,15.60748036702474,10.731187184651693,8.304683685302734,7.047036488850911,6.34877077738444,5.919837951660156,5.622165044148763,5.389952341715495,5.191807111104329,5.012698173522949,4.845383326212565,4.686334292093913,4.533777236938477,4.3867950439453125,4.244871457417806,4.107671737670898,3.9749749501546225,3.8465938568115234,3.7223758697509766,3.6021753946940103,3.485860506693522,3.373302459716797,3.264378547668457,3.158973058064779,3.0569705963134766,2.958263079325358,2.8627405166625977,2.7703065872192383,2.680854161580404,2.5942912101745605,2.5105207761128745,2.4294578234354653,2.35101318359375,2.275098959604899,2.201637585957845,2.1305481592814126,2.061752955118815,1.9951807657877605,1.9307575225830078,1.8684142430623372,1.8080841700236003,1.7497018178304036,1.6932056744893391,1.6385321617126465,1.5856246948242188,1.5344260533650715,1.4848801294962566,1.4369336764017742,1.390536944071452,1.345636208852132,1.3021859327952068,1.2601385116577148,1.2194503943125408,1.180074691772461,1.141970952351888,1.105096975962321,1.0694139798482258,1.0348828633626301,1.0014669100443523,0.9691315491994222,0.9378383159637451,0.9075543880462646,0.8782496452331543,0.8498925367991129,0.8224496046702067,0.7958931922912598,0.7701944510142008,0.7453249295552572,0.7212590376536051,0.6979697545369467,0.6754321257273356,0.6536240975062052,0.6325188080469767,0.6120955149332682,0.5923311710357666,0.5732046763102213,0.5546963612238566,0.5367857615152994,0.5194528500239054,0.5026797453562418,0.48644832770029706,0.47074143091837567,0.45554085572560626,0.44083233674367267,0.4265981117884318,0.4128234386444092,0.39949313799540204,0.38659369945526123,0.37411073843638104,0.3620313008626302,0.35034135977427167,0.3390287160873413,0.32808228333791095,0.31748799482981366,0.30723677078882855,0.2973159948984782,0.2877166271209717,0.2784256339073181,0.2694355845451355,0.26073559125264484,0.25231635570526123,0.2441693147023519,0.2362857460975647,0.2286550005276998,0.22127264738082886,0.2141274611155192,0.20721322298049927,0.20052242279052734,0.19404772917429605,0.18778284390767416,0.18171886603037515,0.17585144440333048,0.1701728900273641,0.16467840472857156,0.15936142206192017,0.15421560406684875,0.1492355465888977,0.14441697796185812,0.13975377877553305,0.1352412005265554,0.1308744748433431,0.12664854526519775,0.12255886197090149,0.11860162019729614,0.11477189262708028,0.11106602350870769,0.1074798305829366,0.10400945941607158,0.10065125425656636,0.0974010427792867,0.094256192445755,0.09121283888816833,0.08826782306035359,0.08541710178057353,0.08265923460324605,0.07999037206172943,0.0774071713288625,0.07490820686022441,0.07248908281326294,0.07014852265516917,0.06788329283396403,0.0656915009021759,0.06357033054033916,0.06151752173900604,0.059531524777412415,0.057609349489212036,0.05574889977773031,0.05394882460435232,0.05220677455266317,0.050521209836006165,0.04888991514841715,0.04731108248233795,0.04578358928362528,0.04430514574050903,0.04287450512250265,0.041490244368712105,0.040150431295235954,0.038853789369265236,0.03759955366452535,0.036385588347911835,0.03521033128102621,0.03407367070515951,0.03297344843546549,0.03190869837999344,0.03087823341290156,0.029881323377291363,0.028916473189989727,0.02798288067181905,0.027079284191131592,0.026204923788706463,0.025358736515045166,0.0245397686958313,0.023747548460960388,0.022980724771817524,0.022238656878471375,0.021520694096883137,0.020825695246458054,0.020153204600016277,0.01950241004427274,0.018872711807489395,0.018263496458530426,0.01767372464140256,0.017103018860022228,0.01655079796910286,0.016016319394111633,0.015499151001373926,0.014998854448397955,0.01451434443394343,0.0140458382666111,0.013592217117547989,0.013153371711572012,0.012728646397590637,0.012317672371864319,0.011919991423686346,0.011534983913103739,0.011162503312031427,0.010802139838536581,0.01045321300625801,0.010115797321001688,0.009789235269029936,0.009473064914345741,0.009167200575272242,0.008871295799811682,0.008584834635257721,0.008307584871848425,0.008039301882187525,0.0077797553191582365,0.007528664544224739,0.0072854602088530855,0.0070501286536455154,0.006822540735205014,0.006602253764867783,0.006389108176032702,0.006182834506034851,0.005983113621671994,0.005789991468191147,0.005602961406111717,0.005422044545412064,0.005246991291642189,0.005077561363577843,0.004913552974661191,0.004754948740204175,0.0046014295270045595,0.004452864949901898,0.004308953570822875,0.004169975717862447,0.004035243143637975,0.0039049688105781875,0.0037789385144909224,0.003656879998743534,0.003538790779809157,0.0034245243296027184,0.0033139834801355996,0.003206960236032804,0.0031034238636493683,0.003003180647889773,0.002906197061141332,0.002812395803630352,0.002721591852605343,0.002633660100400448,0.002548579126596451,0.002466367557644844,0.002386681114633878,0.002309627986202637,0.002235022373497486,0.0021628299728035927,0.0020930368142823377,0.002025502733886242,0.0019600428640842438,0.0018967663248380025,0.0018355002005894978,0.0017762696370482445,0.001718868191043536,0.0016633650908867519,0.0016096772936483224,0.0015577102700869243,0.0015073999141653378,0.001458762524028619,0.0014115860685706139,0.0013660710925857227,0.0013219481334090233,0.0012792691898842652,0.0012379710872968037,0.0011979853734374046,0.0011592754162847996,0.0011218488992502291,0.0010856655426323414,0.001050599617883563,0.0010166928792993228,9.838182013481855E-4,9.520462869356076E-4,9.213085286319256E-4,8.915871536980072E-4,8.627988863736391E-4,8.348923486967882E-4,8.079798426479101E-4,7.819035090506077E-4,7.566167817761501E-4,7.322271509716908E-4,7.085586742808422E-4,6.856989736358324E-4,6.635686537871758E-4,6.421103219812115E-4,6.21374735298256E-4,6.013170350342989E-4,5.819041980430484E-4,5.631356810530027E-4,5.449300321439902E-4,5.273413456355532E-4,5.102880919973055E-4,4.93840198032558E-4,4.7788035590201616E-4,4.624731373041868E-4,4.475133415932457E-4,4.3307989835739136E-4,4.1908700950443745E-4,4.055569103608529E-4,3.9247958920896053E-4,3.797911340370774E-4,3.675330275048812E-4,3.556611482053995E-4,3.441635441655914E-4,3.3304976144184667E-4,3.2232348651935655E-4,3.1191194041942555E-4,3.0183805696045357E-4,2.9209609298656386E-4,2.8265775957455236E-4,2.735319818990926E-4,2.646829040410618E-4,2.561455670123299E-4,2.4786702124401927E-4,2.398754198414584E-4,2.3214288133506974E-4,2.2465075987080732E-4,2.1737959468737245E-4,2.1036675510307154E-4,2.035484261189898E-4,1.9698766603445014E-4,1.9063916988670826E-4,1.8446834292262793E-4,1.78526834739993E-4,1.7276666282365719E-4,1.6717492447545132E-4,1.6177937504835427E-4,1.5655466510603824E-4,1.5151834425826868E-4,1.4659886558850607E-4,1.4187903919567665E-4,1.3728163321502507E-4,1.3285350481358668E-4,1.2857260298915207E-4,1.244319719262421E-4,1.2039858847856522E-4,1.1652091052383184E-4,1.1275283759459853E-4,1.0910539034133156E-4,1.0557984933257103E-4,1.0218856429370742E-4,9.888625936582685E-5,9.568216046318412E-5,9.25910232278208E-5,8.960879252602656E-5,8.670054376125336E-5,8.39218555483967E-5,8.121246840649594E-5,7.858544995542616E-5,7.603988342452794E-5,7.359693214918177E-5,7.12233401524524E-5,6.890866400984426E-5,6.669792734707396E-5,6.453543513392408E-5,6.244915130082518E-5,6.043908554905405E-5,5.847895711970826E-5,5.659762246068567E-5,5.4765449021942914E-5,5.300134944263846E-5,5.128852596196035E-5,4.962842407015463E-5,4.801806062459946E-5,4.6474883371653654E-5,4.497334399881462E-5,4.352420122207453E-5,4.211349490409096E-5,4.075310910896709E-5,3.944709897041321E-5,3.81652838162457E-5,3.6935411723485835E-5,3.573924186639488E-5,3.459340465875963E-5,3.3478509673538305E-5,3.2390288348930575E-5,3.1343185886119805E-5,3.033504617633298E-5,2.9351790241586666E-5,2.8410181888223935E-5,2.748716603188465E-5,2.6599765988066792E-5,2.5743157796872158E-5,2.491654110296319E-5,2.411436920131867E-5,2.3330523011585076E-5,2.257535622144739E-5,2.1851752535440028E-5,2.11454025702551E-5,2.046057488769293E-5,1.980126035050489E-5,1.915778072240452E-5,1.8542409331227343E-5,1.793847089478125E-5,1.736518242978491E-5,1.6806078444157418E-5,1.6257288128448028E-5,1.5737126280631248E-5,1.5226987064428007E-5,1.4739993882055083E-5,1.4262710465118289E-5,1.3803667873920252E-5,1.3353876662828649E-5,1.2918752569627637E-5,1.250546362522679E-5,1.2096131589108458E-5,1.1710460967151448E-5,1.1331518180668354E-5,1.096644094407869E-5,1.061353517191795E-5,1.0270324613278111E-5,9.936501858949972E-6,9.617210404636959E-6,9.3043587791423E-6,9.005289030028507E-6,8.714724875365695E-6,8.42966376997841E-6,8.162978095545744E-6,7.895951057435013E-6,7.644179883451821E-6,7.399825335596688E-6,7.157322518954364E-6,6.926423035717259E-6,6.70489377322762E-6,6.485144695034251E-6,6.2762495266118394E-6,6.075827210831146E-6,5.8770043930659694E-6,5.690656204630311E-6,5.505544928989063E-6,5.328305026826759E-6,5.154134366118039E-6,4.987262097226146E-6,4.8259898903779685E-6,4.669380359700881E-6,4.5197099704334205E-6,4.37481079037146E-6,4.2325700633227825E-6,4.096604243386537E-6,3.96336721072051E-6,3.836055536036535E-6,3.711392309924122E-6,3.5920378043859578E-6,3.477197121052692E-6,3.3656579034868628E-6,3.254857195618873E-6,3.149134196670881E-6,3.05050101208811E-6,2.950545725373862E-6,2.8554059099406004E-6,2.7621290428214706E-6,2.6735130328840264E-6,2.588073281610074E-6,2.501415868512898E-6,2.4220959555047252E-6,2.344279285656133E-6,2.269080141559243E-6,2.1954856492811814E-6,2.1257722740604854E-6,2.0548726145837768E-6,1.989070066580704E-6,1.92469284835776E-6,1.8639202608028427E-6,1.801812686608173E-6,1.7443568746481712E-6,1.6881158444448374E-6,1.6318399502779357E-6,1.5812017106024239E-6,1.5291470845113508E-6,1.4803645171923563E-6,1.4335352413278695E-6,1.386615925487907E-6,1.3425548483307164E-6,1.2982648816735793E-6,1.2568920434811541E-6,1.2154423529864289E-6,1.176668623277995E-6,1.1386061184263478E-6,1.1030504841376871E-6,1.0674303515164258E-6,1.0312972638833646E-6,9.987688827095553E-7,9.677857330340582E-7,9.354104501350472E-7,9.047187935114683E-7,8.753093728349389E-7,8.483067783042012E-7,8.208438278719162E-7,7.940310903601736E-7,7.675339475099463E-7,7.439946330123348E-7,7.201228224100001E-7,6.958923677302664E-7,6.736370323778829E-7,6.5264142297868E-7,6.311814407429969E-7,6.101669593287321E-7,5.909979184555899E-7,5.720467015635222E-7,5.529085835102402E-7]};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {\"title\":\"loss by time\"};\n",
       "\n",
       "  Plotly.plot('plot-1447757220', data, layout);\n",
       "})();\n",
       "});\n",
       "      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres15\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"plot-1447757220\"\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scatter(lossByTime.indices, lossByTime).plot(title = \"loss by time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these iterations, the loss should be close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mTestQuestions\u001b[39m: \u001b[32mINDArray\u001b[39m = [3.00, 6.00, 9.00]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val TestQuestions: INDArray = {\n",
    "  import org.nd4s.Implicits._\n",
    "  Array(Array(3, 6, 9)).toNDArray\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres17\u001b[39m: \u001b[32mINDArray\u001b[39m = 12.00"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Await.result(iqTestRobot(TestQuestions).predict.toScalaFuture, Duration.Inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be close to `12`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also see the value of weights in the trained neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mweightData\u001b[39m: \u001b[32mINDArray\u001b[39m = [-0.55, 0.11, 1.44]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val weightData: INDArray = robotWeight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this article, we have created a IQ test robot with the help of DeepLearning.scala.\n",
    "\n",
    "The model of robot is linear regression with a square loss, which consists of some `INDArryWeight`s and `INDArrayLayer`s.\n",
    "\n",
    "After many iterations of `train`ing, the robot finally learnt the pattern of arithmetic progression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
