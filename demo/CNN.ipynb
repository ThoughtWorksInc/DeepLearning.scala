{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "In this article, we will build a three-layers model for visual recognition. The three-layers model contains a convolutional layer and two full connection layers.\n",
    "\n",
    "We will use the training set of [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) to train the model, finally use the test set to verify the accuracy of the model.\n",
    "\n",
    "The model will achieve 40% accuracy.\n",
    "\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the previous course [GettingStarted](https://thoughtworksinc.github.io/DeepLearning.scala/demo/GettingStarted.html), we need to introduce each class of DeepLearning.scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <script type=\"text/javascript\">\n",
       "        require.config({\n",
       "  paths: {\n",
       "    d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min',\n",
       "    plotly: 'https://cdn.plot.ly/plotly-1.12.0.min'\n",
       "  },\n",
       "\n",
       "  shim: {\n",
       "    plotly: {\n",
       "      deps: ['d3', 'jquery'],\n",
       "      exports: 'plotly'\n",
       "    }\n",
       "  }\n",
       "});\n",
       "        \n",
       "\n",
       "        require(['plotly'], function(Plotly) {\n",
       "          window.Plotly = Plotly;\n",
       "        });\n",
       "      </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                     \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                             \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                             \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$plugin.$                                            \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.element._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.layout._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mplotly.JupyterScala._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.api.ndarray.INDArray\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.nd4j.linalg.factory.Nd4j\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.DeepLearning\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.plugins._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.feature.Factory\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.Await\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.duration.Duration\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.each.Monadic._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscalaz.std.stream._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.concurrent.Executors\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.concurrent.ExecutionContext\n",
       "\u001b[39m\n",
       "\u001b[36msingleThreadExecutor\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mutil\u001b[39m.\u001b[32mconcurrent\u001b[39m.\u001b[32mExecutorService\u001b[39m = java.util.concurrent.Executors$FinalizableDelegatedExecutorService@3a733677\n",
       "\u001b[36msingleThreadExecutionContext\u001b[39m: \u001b[32mconcurrent\u001b[39m.\u001b[32mExecutionContextExecutor\u001b[39m = scala.concurrent.impl.ExecutionContextImpl@6cc74c0f"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.nd4j::nd4s:0.8.0`\n",
    "import $ivy.`org.nd4j:nd4j-native-platform:0.8.0`\n",
    "import $ivy.`com.chuusai::shapeless:2.3.2`\n",
    "import $ivy.`org.rauschig:jarchivelib:0.5.0`\n",
    "import $ivy.`com.thoughtworks.deeplearning::plugins-builtins:2.0.1`\n",
    "import $ivy.`org.plotly-scala::plotly-jupyter-scala:0.3.2`\n",
    "import $ivy.`com.thoughtworks.each::each:3.3.1`\n",
    "import $ivy.`com.thoughtworks.each:each_2.11:3.3.1`\n",
    "import $plugin.$ivy.`org.scalamacros:paradise_2.11.11:2.1.0`\n",
    "\n",
    "import plotly._\n",
    "import plotly.element._\n",
    "import plotly.layout._\n",
    "import plotly.JupyterScala._\n",
    "plotly.JupyterScala.init()\n",
    "\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import com.thoughtworks.deeplearning.DeepLearning\n",
    "import com.thoughtworks.deeplearning.plugins._\n",
    "import com.thoughtworks.feature.Factory\n",
    "import com.thoughtworks.future._\n",
    "import scala.concurrent.Await\n",
    "import scala.concurrent.duration.Duration\n",
    "import com.thoughtworks.each.Monadic._\n",
    "import scalaz.std.stream._\n",
    "\n",
    "import java.util.concurrent.Executors\n",
    "import scala.concurrent.ExecutionContext\n",
    "val singleThreadExecutor = Executors.newSingleThreadExecutor()\n",
    "implicit val singleThreadExecutionContext = ExecutionContext.fromExecutor(singleThreadExecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the line numbers outputted by `jupyter-scala` and to make sure that the page output will not be too long, we need to set `pprintConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprintConfig() = pprintConfig().copy(height = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate need to be set for the full connection layer. Learning rate visually describes the change rate of `weight`. A too-low learning rate will result in slow decrease of `loss`, which will require longer time for training; A too-high learning rate will result in rapid decrease of `loss` at first while fluctuation around the lowest point afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mINDArrayLearningRatePluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/Rabenda/f06279e648e45bd574dc382abb4c44ac/raw/7bd7a871030988c58524108c5985f71002f82012/INDArrayLearningRate.sc\"\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val INDArrayLearningRatePluginUrl = \"https://gist.githubusercontent.com/Rabenda/f06279e648e45bd574dc382abb4c44ac/raw/7bd7a871030988c58524108c5985f71002f82012/INDArrayLearningRate.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(INDArrayLearningRatePluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mCNNsPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.github.com/Atry/15b7d9a4c63d95ad3d67e94bf20b4f69/raw/59f7ee4dff0dde3753f560633574265e950edc93/CNN.sc\"\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val CNNsPluginUrl = \"https://gist.github.com/Atry/15b7d9a4c63d95ad3d67e94bf20b4f69/raw/59f7ee4dff0dde3753f560633574265e950edc93/CNN.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(CNNsPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mL2RegularizationPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/TerrorJack/a60ff752270c40a6485ee787837390aa/raw/119cbacb29dc12d74ae676b4b02687a8f38b02e4/L2Regularization.sc\"\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val L2RegularizationPluginUrl = \"https://gist.githubusercontent.com/TerrorJack/a60ff752270c40a6485ee787837390aa/raw/119cbacb29dc12d74ae676b4b02687a8f38b02e4/L2Regularization.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(L2RegularizationPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mAdamPluginUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://gist.githubusercontent.com/Rabenda/0c2fc6ba4cfa536e4788112a94200b50/raw/233cbc83932dad659519c80717d145a3983f57e1/Adam.sc\"\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val AdamPluginUrl = \"https://gist.githubusercontent.com/Rabenda/0c2fc6ba4cfa536e4788112a94200b50/raw/233cbc83932dad659519c80717d145a3983f57e1/Adam.sc\"\n",
    "interp.load(scala.io.Source.fromURL(new java.net.URL(AdamPluginUrl)).mkString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// `interp.load` is a workaround for https://github.com/lihaoyi/Ammonite/issues/649 and https://github.com/scala/bug/issues/10390\n",
    "interp.load(\"\"\"\n",
    "  val hyperparameters = Factory[Builtins with CNNs with L2Regularization  with Adam with INDArrayLearningRate ].\n",
    "   newInstance(learningRate = 1e-4, l2Regularization = 0.000001)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About softmax classifier, let's see [SoftmaxLinearClassifier](http://deeplearning.thoughtworks.school/demo/SoftmaxLinearClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.implicits._\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayLayer\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msoftmax\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayLayer\n",
    "\n",
    "def softmax(scores: INDArrayLayer): INDArrayLayer = {\n",
    "  val expScores = hyperparameters.exp(scores)\n",
    "  (expScores + 1e-8) / (expScores.sum(1) + 1e-8)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the images and corresponding label information for test data from CIFAR10 database and process them, we need [Cifar10](https://github.com/ThoughtWorksInc/Cifar10.scala). This library contains the read and processed CIFAR10 data, provided in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing data to the model, we need process label data with ([one hot encoding](https://en.wikipedia.org/wiki/One-hot)): transform INDArray of `NumberOfPixels × 1` into INDArray of `NumberOfPixels × NumberOfClasses`. The value of correct classification corresponding to each line is 1, and the values of other columns are 0. The reason for differentiating the training set and test set is to make it clear that whether the network is over trained which leads to [overfitting](https://en.wikipedia.org/wiki/Overfitting). \n",
    "\n",
    "But [Cifar10](https://github.com/ThoughtWorksInc/Cifar10.scala) also process the above content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                                 \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.deeplearning.etl.Cifar10\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.thoughtworks.future._\n",
       "\u001b[39m\n",
       "\u001b[36mcifar10\u001b[39m: \u001b[32mcom\u001b[39m.\u001b[32mthoughtworks\u001b[39m.\u001b[32mdeeplearning\u001b[39m.\u001b[32metl\u001b[39m.\u001b[32mCifar10\u001b[39m = \u001b[33mCifar10\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.thoughtworks.deeplearning.etl::cifar10:1.1.0`\n",
    "import com.thoughtworks.deeplearning.etl.Cifar10\n",
    "import com.thoughtworks.future._\n",
    "val cifar10 = Cifar10.load().blockingAwait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose your  neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all layers and [initialize Weight](https://github.com/ThoughtWorksInc/DeepLearning.scala/wiki/Getting-Started#231--weight-intialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.INDArrayWeight\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.INDArrayWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mNumberOfClasses\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m10\u001b[39m\n",
       "\u001b[36mNumberOfPixels\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3072\u001b[39m\n",
       "\u001b[36mKernelSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mKernelWidth\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mKernelHeight\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m7\u001b[39m\n",
       "\u001b[36mNumFilters\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m32\u001b[39m\n",
       "\u001b[36mHiddenDim\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m500\u001b[39m\n",
       "\u001b[36mWeightScale\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.01\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mPixelHeight\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mPixelWidth\u001b[39m\n",
       "\u001b[36mPadding\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m3\u001b[39m\n",
       "\u001b[36mStride\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1\u001b[39m\n",
       "\u001b[36mPoolSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m2\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val NumberOfClasses: Int = 10\n",
    "val NumberOfPixels: Int = 3072\n",
    "val KernelSize: Int = 7\n",
    "val KernelWidth: Int = KernelSize\n",
    "val KernelHeight: Int = KernelSize\n",
    "val NumFilters: Int = 32\n",
    "val HiddenDim: Int = 500 //define hidden_layer->affineRuleOfCnnLayer\n",
    "val WeightScale: Double = 1e-2 \n",
    "def PixelHeight = Cifar10.Height\n",
    "def PixelWidth = Cifar10.Width\n",
    "val Padding: Int = (KernelSize - 1) / 2\n",
    "val Stride: Int = 1\n",
    "val PoolSize: Int = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mAllWeightsAndBias\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object AllWeightsAndBias {\n",
    "    import org.nd4s.Implicits._\n",
    "    val cnnWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(NumFilters, Cifar10.NumberOfChannels, KernelHeight, KernelWidth)) * WeightScale)\n",
    "    val cnnBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(NumFilters))\n",
    "    val affineWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(NumFilters * (PixelHeight / PoolSize) * (PixelWidth / PoolSize), HiddenDim)) * WeightScale)\n",
    "    val affineBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(HiddenDim))\n",
    "    val affineLastWeight: INDArrayWeight = INDArrayWeight(Nd4j.randn(Array(HiddenDim, Cifar10.NumberOfClasses)) * WeightScale)\n",
    "    val affineLastBias: INDArrayWeight = INDArrayWeight(Nd4j.zeros(Cifar10.NumberOfClasses))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mAllWeightsAndBias._\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import AllWeightsAndBias._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36maffine\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrelu\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def affine(input: INDArrayLayer, weight: INDArrayWeight, bias: INDArrayWeight): INDArrayLayer = {\n",
    "    input dot weight + bias\n",
    "}\n",
    "\n",
    "def relu(input: INDArrayLayer): INDArrayLayer = {\n",
    "    import hyperparameters.max\n",
    "    max(input, 0.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mmyNeuralNetwork\u001b[39m"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def myNeuralNetwork(input: INDArray):  INDArrayLayer = {\n",
    "    import hyperparameters.max\n",
    "    import hyperparameters.maxPool\n",
    "    import hyperparameters.conv2d\n",
    "    \n",
    "    val cnnLayer = maxPool(relu(conv2d(input.reshape(input.shape()(0), Cifar10.NumberOfChannels, PixelHeight, PixelWidth), cnnWeight, cnnBias, (KernelHeight, KernelWidth), (Stride, Stride), (Padding, Padding))), (PoolSize, PoolSize))\n",
    "\n",
    "    val affineRuleOfCnnLayer = relu(affine(cnnLayer.reshape(input.shape()(0), NumFilters * (PixelHeight / PoolSize) * (PixelWidth / PoolSize)), affineWeight, affineBias))\n",
    "\n",
    "    val affineOfaffineRuleOfCnnLayer = affine(affineRuleOfCnnLayer.reshape(input.shape()(0), HiddenDim), affineLastWeight, affineLastBias)\n",
    "\n",
    "    val softmaxValue = softmax(affineOfaffineRuleOfCnnLayer)\n",
    "\n",
    "    softmaxValue\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LossFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about the prediction result of the neural network, we need to write the loss function `lossFunction`. We use [cross-entropy loss](https://en.wikipedia.org/wiki/Cross_entropy) to make comparison between this result and the actual result before return the score. Formula:\n",
    "![](https://zhihu.com/equation?tex=%5Cdisplaystyle+H%28p%2Cq%29%3D-%5Csum_xp%28x%29+logq%28x%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mhyperparameters.DoubleLayer\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mlossFunction\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperparameters.DoubleLayer\n",
    "\n",
    "def lossFunction(input: INDArray, expectOutput: INDArray): DoubleLayer = { \n",
    "    val probabilities = myNeuralNetwork(input)\n",
    "    -(hyperparameters.log(probabilities) * expectOutput).mean   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To observe the training process of the neural network, we need to output `loss`; while training the neural network, the `loss` shall be decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTrainer\u001b[39m"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Trainer(batchSize: Int, numberOfEpoches: Int = 5) {\n",
    "    import scalaz.std.anyVal._\n",
    "    import scalaz.syntax.all._\n",
    "    @volatile\n",
    "    private var isShuttingDown: Boolean = false\n",
    "\n",
    "    private val lossBuffer = scala.collection.mutable.Buffer.empty[Double]\n",
    "        \n",
    "    def plotLoss(): Unit = Seq(Scatter(lossBuffer.indices, lossBuffer)).plot(title = \"loss by time\")\n",
    "    \n",
    "    def interrupt(): Unit = isShuttingDown = true\n",
    "\n",
    "    def startTrain(): Unit = {\n",
    "\n",
    "        @monadic[Future]\n",
    "        def trainTask: Future[Unit] = {\n",
    "            isShuttingDown = false\n",
    "            var epoch = 0\n",
    "            \n",
    "            while (epoch < numberOfEpoches && !isShuttingDown) {\n",
    "                val cifar10 = Cifar10.load().blockingAwait\n",
    "                val iterator = cifar10.epoch(batchSize).zipWithIndex\n",
    "                while (iterator.hasNext && !isShuttingDown) {\n",
    "                    val (Cifar10.Batch(labels, batch), i) = iterator.next()\n",
    "                    val loss = lossFunction(batch, labels).train.each\n",
    "                    lossBuffer += loss\n",
    "                    hyperparameters.logger.info(s\"epoch=$epoch iteration=$i batchSize=$batchSize loss=$loss\")\n",
    "                }\n",
    "                epoch += 1\n",
    "            }\n",
    "            hyperparameters.logger.info(\"Done\")\n",
    "        }\n",
    "        trainTask.onComplete { tryUnit: scala.util.Try[Unit] => tryUnit.get }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainBatchSize\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m50\u001b[39m\n",
       "\u001b[36mtrainer\u001b[39m: \u001b[32mTrainer\u001b[39m = $sess.cmd22Wrapper$Helper$Trainer@efdf81b"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainBatchSize = 50\n",
    "\n",
    "val trainer = new Trainer(batchSize = trainBatchSize, numberOfEpoches = 1)\n",
    "trainer.startTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// trainer.interrupt()  //This can interrupt train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"chart\" id=\"plot-634520798\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "requirejs([\"plotly\"], function(Plotly) {\n",
       "  (function () {\n",
       "  var data0 = {\"type\":\"scatter\",\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0,55.0,56.0,57.0,58.0,59.0,60.0,61.0,62.0,63.0,64.0,65.0,66.0,67.0,68.0,69.0,70.0,71.0,72.0,73.0,74.0,75.0,76.0,77.0,78.0,79.0,80.0,81.0,82.0,83.0,84.0,85.0,86.0,87.0,88.0,89.0,90.0,91.0,92.0,93.0,94.0,95.0,96.0,97.0,98.0,99.0,100.0,101.0,102.0,103.0,104.0,105.0,106.0,107.0,108.0,109.0,110.0,111.0,112.0,113.0,114.0,115.0,116.0,117.0,118.0,119.0,120.0,121.0,122.0,123.0,124.0,125.0,126.0,127.0,128.0,129.0,130.0,131.0,132.0,133.0,134.0,135.0,136.0,137.0,138.0,139.0,140.0,141.0,142.0,143.0,144.0,145.0,146.0,147.0,148.0,149.0,150.0,151.0,152.0,153.0,154.0,155.0,156.0,157.0,158.0,159.0,160.0,161.0,162.0,163.0,164.0,165.0,166.0,167.0,168.0,169.0,170.0,171.0,172.0,173.0,174.0,175.0,176.0,177.0,178.0,179.0,180.0,181.0,182.0,183.0,184.0,185.0,186.0,187.0,188.0,189.0,190.0,191.0,192.0,193.0,194.0,195.0,196.0,197.0,198.0,199.0,200.0,201.0,202.0,203.0,204.0,205.0,206.0,207.0,208.0,209.0,210.0,211.0,212.0,213.0,214.0,215.0,216.0,217.0,218.0,219.0,220.0,221.0,222.0,223.0,224.0,225.0,226.0,227.0,228.0,229.0,230.0,231.0,232.0,233.0,234.0,235.0,236.0,237.0,238.0,239.0,240.0,241.0,242.0,243.0,244.0,245.0,246.0,247.0,248.0,249.0,250.0,251.0,252.0,253.0,254.0,255.0,256.0,257.0,258.0,259.0,260.0,261.0,262.0,263.0,264.0,265.0,266.0,267.0,268.0,269.0,270.0,271.0,272.0,273.0,274.0,275.0,276.0,277.0,278.0,279.0,280.0,281.0,282.0,283.0,284.0,285.0,286.0,287.0,288.0,289.0,290.0,291.0,292.0,293.0,294.0,295.0,296.0,297.0,298.0,299.0,300.0,301.0,302.0,303.0,304.0,305.0,306.0,307.0,308.0,309.0,310.0,311.0,312.0,313.0,314.0,315.0,316.0,317.0,318.0,319.0,320.0,321.0,322.0,323.0,324.0,325.0,326.0,327.0,328.0,329.0,330.0,331.0,332.0,333.0,334.0,335.0,336.0,337.0,338.0,339.0,340.0,341.0,342.0,343.0,344.0,345.0,346.0,347.0,348.0,349.0,350.0,351.0,352.0,353.0,354.0,355.0,356.0,357.0,358.0,359.0,360.0,361.0,362.0,363.0,364.0,365.0,366.0,367.0,368.0,369.0,370.0,371.0,372.0,373.0,374.0,375.0,376.0,377.0,378.0,379.0,380.0,381.0,382.0,383.0,384.0,385.0,386.0,387.0,388.0,389.0,390.0,391.0,392.0,393.0,394.0,395.0,396.0,397.0,398.0,399.0,400.0,401.0,402.0,403.0,404.0,405.0,406.0,407.0,408.0,409.0,410.0,411.0,412.0,413.0,414.0,415.0,416.0,417.0,418.0,419.0,420.0,421.0,422.0,423.0,424.0,425.0,426.0,427.0,428.0,429.0,430.0,431.0,432.0,433.0,434.0,435.0,436.0,437.0,438.0,439.0,440.0,441.0,442.0,443.0,444.0,445.0,446.0,447.0,448.0,449.0,450.0,451.0,452.0,453.0,454.0,455.0,456.0,457.0,458.0,459.0,460.0,461.0,462.0,463.0,464.0,465.0,466.0,467.0,468.0,469.0,470.0,471.0,472.0,473.0,474.0,475.0,476.0,477.0,478.0,479.0,480.0,481.0,482.0,483.0,484.0,485.0,486.0,487.0,488.0,489.0,490.0,491.0,492.0,493.0,494.0,495.0,496.0,497.0,498.0,499.0,500.0,501.0,502.0,503.0,504.0,505.0,506.0,507.0,508.0,509.0,510.0,511.0,512.0,513.0,514.0,515.0,516.0,517.0,518.0,519.0,520.0,521.0,522.0,523.0,524.0,525.0,526.0,527.0,528.0,529.0,530.0,531.0,532.0,533.0,534.0,535.0,536.0,537.0,538.0,539.0,540.0,541.0,542.0,543.0,544.0,545.0,546.0,547.0,548.0,549.0,550.0,551.0,552.0,553.0,554.0,555.0,556.0,557.0,558.0,559.0,560.0,561.0,562.0,563.0,564.0,565.0,566.0,567.0,568.0,569.0,570.0,571.0,572.0,573.0,574.0,575.0,576.0,577.0,578.0,579.0,580.0,581.0,582.0,583.0,584.0,585.0,586.0,587.0,588.0,589.0,590.0,591.0,592.0,593.0,594.0,595.0,596.0,597.0,598.0,599.0,600.0,601.0,602.0,603.0,604.0,605.0,606.0,607.0,608.0,609.0,610.0,611.0,612.0,613.0,614.0,615.0,616.0,617.0,618.0,619.0,620.0,621.0,622.0,623.0,624.0,625.0,626.0,627.0,628.0,629.0,630.0,631.0,632.0,633.0,634.0,635.0,636.0,637.0,638.0,639.0,640.0,641.0,642.0,643.0,644.0,645.0,646.0,647.0,648.0,649.0,650.0,651.0,652.0,653.0,654.0,655.0,656.0,657.0,658.0,659.0,660.0,661.0,662.0,663.0,664.0,665.0,666.0,667.0,668.0,669.0,670.0,671.0,672.0,673.0,674.0,675.0,676.0,677.0,678.0,679.0,680.0,681.0,682.0,683.0,684.0,685.0,686.0,687.0,688.0,689.0,690.0,691.0,692.0,693.0,694.0,695.0,696.0,697.0,698.0,699.0,700.0,701.0,702.0,703.0,704.0,705.0,706.0,707.0,708.0,709.0,710.0,711.0,712.0,713.0,714.0,715.0,716.0,717.0,718.0,719.0,720.0,721.0,722.0,723.0,724.0,725.0,726.0,727.0,728.0,729.0,730.0,731.0,732.0,733.0,734.0,735.0,736.0,737.0,738.0,739.0,740.0,741.0,742.0,743.0,744.0,745.0,746.0,747.0,748.0,749.0,750.0,751.0,752.0,753.0,754.0,755.0,756.0,757.0,758.0,759.0,760.0,761.0,762.0,763.0,764.0,765.0,766.0,767.0,768.0,769.0,770.0,771.0,772.0,773.0,774.0,775.0,776.0,777.0,778.0,779.0,780.0,781.0,782.0,783.0,784.0,785.0,786.0,787.0,788.0,789.0,790.0,791.0,792.0,793.0,794.0,795.0,796.0,797.0,798.0,799.0,800.0,801.0,802.0,803.0,804.0,805.0,806.0,807.0,808.0,809.0,810.0,811.0,812.0,813.0,814.0,815.0,816.0,817.0,818.0,819.0,820.0,821.0,822.0,823.0,824.0,825.0,826.0,827.0,828.0,829.0,830.0,831.0,832.0,833.0,834.0,835.0,836.0,837.0,838.0,839.0,840.0,841.0,842.0,843.0,844.0,845.0,846.0,847.0,848.0,849.0,850.0,851.0,852.0,853.0,854.0,855.0,856.0,857.0,858.0,859.0,860.0,861.0,862.0,863.0,864.0,865.0,866.0,867.0,868.0,869.0,870.0,871.0,872.0,873.0,874.0,875.0,876.0,877.0,878.0,879.0,880.0,881.0,882.0,883.0,884.0,885.0,886.0,887.0,888.0,889.0,890.0,891.0,892.0,893.0,894.0,895.0,896.0,897.0,898.0,899.0,900.0,901.0,902.0,903.0,904.0,905.0,906.0,907.0,908.0,909.0,910.0,911.0,912.0,913.0,914.0,915.0,916.0,917.0,918.0,919.0,920.0,921.0,922.0,923.0,924.0,925.0,926.0,927.0,928.0,929.0,930.0,931.0,932.0,933.0,934.0,935.0,936.0,937.0,938.0,939.0,940.0,941.0,942.0,943.0,944.0,945.0,946.0,947.0,948.0,949.0,950.0,951.0,952.0,953.0,954.0,955.0,956.0,957.0,958.0,959.0,960.0,961.0,962.0,963.0,964.0,965.0,966.0,967.0,968.0,969.0,970.0,971.0,972.0,973.0,974.0,975.0,976.0,977.0,978.0,979.0,980.0,981.0,982.0,983.0,984.0,985.0,986.0,987.0,988.0,989.0,990.0,991.0,992.0,993.0,994.0,995.0,996.0,997.0,998.0,999.0],\"y\":[0.2302962188720703,0.23010867309570313,0.22896304321289063,0.23269906616210936,0.23422419738769532,0.2301776580810547,0.23063775634765624,0.23012567138671874,0.2303446960449219,0.23017239379882812,0.23023089599609375,0.23024057006835938,0.230029052734375,0.230133544921875,0.22962408447265625,0.23050851440429687,0.22901707458496093,0.22968733215332032,0.22947303771972657,0.23296156311035157,0.23004808044433595,0.22923751831054687,0.2300153350830078,0.2297699737548828,0.2299707336425781,0.22989266967773436,0.2292529754638672,0.23091299438476562,0.22975953674316407,0.2298328857421875,0.22908413696289062,0.2288388671875,0.23055075073242187,0.230318115234375,0.22915573120117189,0.22902720642089844,0.22914324951171874,0.2289287872314453,0.22872854614257812,0.22746389770507813,0.22735075378417968,0.22969358825683595,0.22667828369140625,0.22730975341796875,0.226252197265625,0.22500444030761718,0.2276367645263672,0.22876071166992187,0.22474270629882812,0.22760269165039063,0.2220333251953125,0.22629576110839844,0.22619131469726564,0.22468002319335936,0.2189134521484375,0.2231699981689453,0.22482269287109374,0.21908831787109376,0.21971878051757812,0.2301130828857422,0.2214595947265625,0.2151678924560547,0.22411935424804688,0.2116392822265625,0.21833367919921876,0.21312933349609375,0.21404959106445312,0.21415240478515624,0.21975685119628907,0.20444528198242187,0.21715670776367188,0.20960433959960936,0.20108335876464845,0.2143302001953125,0.20339443969726562,0.21970263671875,0.20220335388183594,0.20668324279785155,0.21408995056152344,0.22161888122558593,0.21182882690429689,0.2005830078125,0.21110203552246093,0.20702236938476562,0.2056720733642578,0.21055331420898438,0.21626089477539062,0.21185212707519532,0.21650363159179686,0.20787728881835937,0.20419639587402344,0.20005740356445312,0.19662091064453124,0.20169094848632813,0.1979376220703125,0.21485264587402345,0.21720358276367188,0.18380859375,0.20156446838378905,0.19021832275390624,0.19943190002441405,0.19940223693847656,0.19195175170898438,0.20475985717773437,0.19629742431640626,0.1990039825439453,0.21710690307617186,0.18892568969726561,0.1895047607421875,0.20858172607421874,0.19332125854492188,0.20087261962890626,0.2045664520263672,0.19565615844726564,0.19844308471679686,0.20380950927734376,0.18565092468261718,0.19825338745117188,0.19007583618164062,0.19673095703125,0.19701936340332032,0.19134788513183593,0.2205082244873047,0.1898413391113281,0.19872671508789064,0.19453150939941405,0.19704635620117186,0.18455035400390624,0.1881165466308594,0.1881029815673828,0.22686013793945312,0.18623236083984376,0.1893600616455078,0.19582998657226564,0.19979788208007812,0.1919129943847656,0.18819775390625,0.1747099609375,0.18525413513183595,0.19441070556640624,0.18155978393554686,0.18007881164550782,0.19633023071289063,0.18284420776367188,0.21258734130859375,0.1863775939941406,0.1772534637451172,0.19038644409179686,0.178611328125,0.22169430541992188,0.19740074157714843,0.18980465698242188,0.1844483642578125,0.1962823181152344,0.19347604370117188,0.18276170349121093,0.22769180297851563,0.19617898559570313,0.1795298156738281,0.1967178955078125,0.19712176513671875,0.19833868408203126,0.18919467163085937,0.19220669555664063,0.18540054321289062,0.18918016052246095,0.17944451904296874,0.16563211059570312,0.16088766479492186,0.16470271301269532,0.1755623779296875,0.19066659545898437,0.19948660278320313,0.16700631713867187,0.1949137878417969,0.20158770751953126,0.18177333068847656,0.17936575317382814,0.18916862487792968,0.18062942504882812,0.18710903930664063,0.17028677368164064,0.16587841796875,0.18695681762695313,0.1731606140136719,0.16624691772460937,0.1915750732421875,0.1743315887451172,0.17349737548828126,0.1568693389892578,0.18386465454101564,0.18590574645996094,0.1773713684082031,0.19269990539550783,0.178024169921875,0.17999407958984376,0.1681888427734375,0.1919796142578125,0.18006553649902343,0.1762847900390625,0.16661834716796875,0.1778004150390625,0.17787481689453125,0.19044329833984375,0.17708013916015625,0.19308328247070314,0.20659942626953126,0.17657369995117186,0.1514074401855469,0.1761396942138672,0.18108815002441406,0.18472772216796876,0.1637810974121094,0.18295079040527343,0.17118472290039063,0.1782605895996094,0.17648944091796875,0.1703729248046875,0.1777352294921875,0.17268865966796876,0.17708346557617188,0.18489944458007812,0.17821286010742188,0.17602772521972657,0.18671473693847657,0.19142041015625,0.18839840698242188,0.19364451599121094,0.19812814331054687,0.18802978515625,0.17513162231445312,0.171180419921875,0.1814743347167969,0.17743229675292968,0.1817215576171875,0.16216835021972656,0.16454371643066407,0.19477081298828125,0.1736597900390625,0.20178630065917968,0.19367446899414062,0.17437417602539063,0.17641046142578126,0.17093846130371093,0.169361572265625,0.17509805297851563,0.18232473754882814,0.1728236999511719,0.18603138732910157,0.15569363403320313,0.15990835571289064,0.1987644500732422,0.1826920928955078,0.16862791442871095,0.18131808471679686,0.17450712585449218,0.17508412170410156,0.17213223266601563,0.15715045166015626,0.19203302001953124,0.16972564697265624,0.16574269104003905,0.1693264923095703,0.18655792236328125,0.1976737365722656,0.17243228149414064,0.19284127807617188,0.16502061462402343,0.1875613708496094,0.18311793518066405,0.17672720336914063,0.18588288879394532,0.1718328857421875,0.18269448852539064,0.1720860595703125,0.16188421630859376,0.18090867614746095,0.16910198974609375,0.15975386047363282,0.16728045654296875,0.17281747436523437,0.165989990234375,0.182686767578125,0.15504806518554687,0.19428219604492186,0.1558564758300781,0.1744717254638672,0.15403521728515626,0.17755050659179689,0.1683478546142578,0.1907669677734375,0.16715243530273438,0.17233662414550782,0.19745991516113282,0.16512115478515624,0.161152099609375,0.17607191467285158,0.1925941619873047,0.1702485046386719,0.1814755859375,0.17944329833984374,0.18047560119628905,0.16092295837402343,0.18822695922851562,0.18526382446289064,0.1724381103515625,0.17735237121582031,0.17793562316894532,0.17098464965820312,0.19524659729003907,0.17343170166015626,0.19011138916015624,0.16305133056640625,0.16739862060546876,0.19152059936523438,0.1783838348388672,0.18013525390625,0.15945355224609375,0.18293011474609375,0.1736951904296875,0.18111874389648439,0.1773591003417969,0.16448416137695313,0.16427581787109374,0.16797518920898438,0.19383282470703125,0.17795538330078126,0.1824384307861328,0.1550201416015625,0.18351077270507812,0.16213284301757813,0.18023818969726563,0.16389599609375,0.17608818054199218,0.18960737609863282,0.1593804931640625,0.18211923217773437,0.17222401428222656,0.15810870361328125,0.17599041748046876,0.1691978759765625,0.16783662414550782,0.17719686889648437,0.17190919494628906,0.17717994689941408,0.17807586669921874,0.16509400939941407,0.16675578308105468,0.18021514892578125,0.18753030395507814,0.176720947265625,0.16381344604492187,0.17353221130371094,0.18497915649414062,0.15282762145996093,0.16929721069335937,0.17882606506347656,0.15904702758789063,0.16196961975097657,0.18429476928710936,0.15493254089355468,0.15245945739746095,0.16329083251953125,0.16922079467773438,0.17974261474609374,0.15716140747070312,0.1698396453857422,0.16096316528320312,0.17379205322265626,0.160890625,0.17777134704589845,0.1770346221923828,0.1715750732421875,0.16232484436035155,0.15837045288085938,0.17047222900390624,0.15985122680664063,0.15503573608398438,0.17541812133789061,0.17138229370117186,0.15098155212402345,0.18777557373046874,0.17279745483398437,0.1848575744628906,0.17009474182128906,0.16592002868652345,0.15375010681152343,0.14093983459472656,0.15697543334960937,0.15660775756835937,0.16376358032226562,0.15745712280273438,0.17837399291992187,0.1591534423828125,0.18231314086914063,0.16530313110351563,0.17388864135742188,0.139634521484375,0.14835189819335937,0.14384130859375,0.15605844116210937,0.16252032470703126,0.17037905883789062,0.18075503540039062,0.16759768676757814,0.19404080200195312,0.1638642578125,0.15346490478515626,0.17271127319335938,0.18216409301757813,0.16804185485839843,0.17691732788085937,0.17254682922363282,0.16889926147460937,0.1640357666015625,0.1542738037109375,0.17315219116210936,0.18303811645507811,0.16177099609375,0.18090383911132812,0.16054200744628908,0.1579661865234375,0.16690182495117187,0.16159931945800782,0.16361013793945312,0.1577809753417969,0.1553187255859375,0.1584093322753906,0.18279766845703124,0.1772269592285156,0.1757533874511719,0.1686112060546875,0.17482565307617187,0.159785400390625,0.15733158874511718,0.17863157653808595,0.15288357543945313,0.14547103881835938,0.16145660400390624,0.16989193725585938,0.17865060424804688,0.14994134521484376,0.14529660034179687,0.16726033020019532,0.18227798461914063,0.15305284118652343,0.16601609802246095,0.16997117614746093,0.16468820190429687,0.16254827880859374,0.1776428985595703,0.15714718627929689,0.1520902862548828,0.16999516296386719,0.17609649658203125,0.16126220703125,0.19018496704101562,0.16864076232910155,0.16344866943359376,0.17236019897460939,0.15561802673339845,0.147947265625,0.1876075439453125,0.18551641845703126,0.15836886596679686,0.16466104125976563,0.18412246704101562,0.16147091674804687,0.154259765625,0.15349754333496093,0.1672171630859375,0.16791452026367187,0.13742117309570312,0.16278472900390625,0.17940406799316405,0.1543839569091797,0.16352407836914062,0.1753121795654297,0.1801590576171875,0.15113050842285156,0.15680276489257813,0.1651549835205078,0.1722685546875,0.15774920654296876,0.13990234375,0.14491331481933595,0.1686004638671875,0.16063636779785156,0.16538160705566407,0.14455853271484376,0.16411228942871095,0.16577226257324218,0.16352896118164062,0.16603729248046875,0.14273921203613282,0.14058160400390626,0.15748980712890626,0.2019077911376953,0.14885470581054688,0.18089350891113282,0.16306082153320312,0.168820556640625,0.16383551025390625,0.1483300018310547,0.15049923706054688,0.15801371765136718,0.15431658935546874,0.15395193481445313,0.18777403259277345,0.16765792846679686,0.1851391143798828,0.15114849853515624,0.14643832397460937,0.16692277526855467,0.18674853515625,0.15177363586425782,0.16044230651855468,0.138187255859375,0.14811712646484376,0.16126913452148436,0.16226416015625,0.15191012573242188,0.1797210693359375,0.15082063293457032,0.16646807861328125,0.15866661071777344,0.18089425659179686,0.15582421875,0.1287603302001953,0.15416575622558593,0.13586579895019532,0.16076760864257814,0.1596783905029297,0.13529678344726562,0.16139891052246094,0.14279153442382814,0.1499981231689453,0.162106201171875,0.16101919555664063,0.15019100952148437,0.13557756042480468,0.15684426879882812,0.1424990997314453,0.15784115600585938,0.160204345703125,0.15186199951171875,0.1532641143798828,0.15549832153320312,0.17410877990722656,0.13468438720703124,0.1584683837890625,0.14669940185546876,0.13164039611816405,0.164854736328125,0.15551165771484374,0.1453348388671875,0.15453414916992186,0.1508643798828125,0.17488751220703125,0.16717001342773438,0.15918855285644531,0.1670858917236328,0.15728028869628907,0.1689012451171875,0.17161006164550782,0.14886076354980468,0.1790985565185547,0.16196661376953125,0.16130233764648438,0.17919435119628907,0.16819276428222657,0.16638742065429687,0.16057994079589843,0.1385454559326172,0.1782572021484375,0.1687686767578125,0.18294096374511717,0.14935781860351563,0.15149484252929687,0.17963937377929687,0.15542620849609376,0.171857177734375,0.1556333770751953,0.1576898193359375,0.16214816284179687,0.1572806396484375,0.17050772094726563,0.16282986450195314,0.173617431640625,0.1501119384765625,0.1457086181640625,0.15262521362304687,0.18231843566894532,0.1472940673828125,0.17484909057617187,0.16583067321777345,0.17103741455078125,0.16630746459960938,0.133756591796875,0.15611260986328124,0.17246044921875,0.1650216522216797,0.15691346740722656,0.15557864379882813,0.173208984375,0.16384269714355468,0.1527193603515625,0.15246273803710939,0.15757441711425782,0.15611326599121095,0.16157122802734375,0.15318910217285156,0.149297607421875,0.14333465576171875,0.16918487548828126,0.16748968505859374,0.1422076416015625,0.16049087524414063,0.165070068359375,0.15359408569335936,0.1690493927001953,0.14184396362304688,0.1533853759765625,0.14988314819335938,0.15485516357421875,0.1814997100830078,0.14340814208984376,0.16046820068359374,0.15433631896972655,0.1637890167236328,0.15369400024414062,0.15767005920410157,0.16354408264160156,0.15051446533203125,0.14065667724609374,0.145734619140625,0.15356068420410157,0.1668633728027344,0.18230584716796874,0.16931060791015626,0.16377117919921874,0.16942840576171875,0.15995474243164062,0.1678432159423828,0.1563963623046875,0.1547625732421875,0.15632302856445313,0.1671607666015625,0.14196725463867188,0.147582275390625,0.15057798767089844,0.15116937255859375,0.14964627075195314,0.16686257934570312,0.16568807983398437,0.16017506408691407,0.14056039428710937,0.17535342407226562,0.162190673828125,0.15355276489257813,0.13903634643554688,0.17141978454589843,0.16230569458007812,0.15069728088378906,0.15066885375976563,0.150149169921875,0.14873995971679688,0.16248025512695313,0.16548275756835937,0.16850376892089844,0.16302813720703124,0.17247975158691406,0.15213568115234374,0.16525369262695314,0.16662872314453125,0.15535800170898437,0.16735043334960936,0.1719027099609375,0.15854830932617187,0.16739619445800782,0.13068344116210937,0.16442544555664063,0.17614389038085937,0.15133761596679687,0.16878086853027344,0.14387075805664062,0.15541970825195311,0.13619834899902344,0.15051373291015624,0.15457760620117186,0.1703028564453125,0.151040283203125,0.15631362915039063,0.15807827758789061,0.1526840362548828,0.1599906005859375,0.14996502685546875,0.15880271911621094,0.16586993408203124,0.1777447967529297,0.15224783325195312,0.1497270812988281,0.13738534545898437,0.13174212646484376,0.16475314331054688,0.1608065948486328,0.13723397827148437,0.15309259033203124,0.15113589477539063,0.17263070678710937,0.1428665313720703,0.14360855102539063,0.15324459838867188,0.13131552124023438,0.14550640869140624,0.151643798828125,0.17021281433105467,0.16243231201171876,0.1769134521484375,0.14927944946289062,0.18677531433105468,0.1652725067138672,0.17534388732910156,0.154841796875,0.13864035034179686,0.16713565063476563,0.16051046752929687,0.15594366455078126,0.14335198974609376,0.177395751953125,0.1611401824951172,0.168991943359375,0.1577481689453125,0.17536288452148438,0.17457798767089844,0.15453182983398436,0.16962797546386718,0.13833587646484374,0.14563478088378906,0.16011146545410157,0.17213616943359375,0.14312344360351562,0.1674554748535156,0.1572324676513672,0.16286297607421876,0.1589365234375,0.17421249389648438,0.14659976196289062,0.13861041259765625,0.15654083251953124,0.14746302795410157,0.13335281372070312,0.17090061950683594,0.16875830078125,0.13958010864257814,0.1455087890625,0.143758056640625,0.18450494384765626,0.1460328369140625,0.17256015014648438,0.13065362548828124,0.13645053100585938,0.16493328857421874,0.1461941680908203,0.13136126708984375,0.14798150634765625,0.15965631103515626,0.13130880737304687,0.1426474609375,0.17240695190429686,0.15858638000488282,0.14552871704101564,0.15518881225585937,0.14575729370117188,0.1655132598876953,0.15122378540039064,0.15210897827148437,0.15763134765625,0.1649464111328125,0.15993492126464845,0.13686141967773438,0.15108013916015625,0.16140403747558593,0.1646719207763672,0.1430675048828125,0.16900881958007813,0.14634951782226563,0.13117625427246093,0.1553294219970703,0.14138958740234375,0.1630765838623047,0.15847518920898437,0.14774501037597657,0.13784979248046875,0.16809248352050782,0.1456871337890625,0.17044113159179688,0.17410751342773437,0.16591246032714843,0.17659165954589845,0.14073558044433593,0.18451893615722656,0.17564248657226564,0.16598678588867188,0.14626937866210937,0.1515465850830078,0.13764675903320311,0.1613138427734375,0.14781613159179688,0.1466824951171875,0.15455020141601564,0.17972369384765624,0.1678745422363281,0.1457257080078125,0.15825694274902344,0.18195933532714845,0.167298095703125,0.15795437622070313,0.15000773620605468,0.14865597534179686,0.14915005493164063,0.1698843231201172,0.157677734375,0.1465042724609375,0.16277947998046874,0.14626943969726564,0.1576118621826172,0.16606704711914064,0.13671875,0.14637620544433594,0.16020803833007813,0.1457181396484375,0.15899468994140625,0.1692996826171875,0.14877862548828125,0.1644298553466797,0.16639109802246094,0.165206298828125,0.16076803588867186,0.132693603515625,0.15863375854492187,0.1723730926513672,0.15053948974609374,0.15460205078125,0.1499251708984375,0.15368988037109374,0.16178016662597655,0.1352711486816406,0.16923403930664063,0.16943971252441406,0.1517463836669922,0.13845790100097657,0.15900543212890625,0.16929658508300782,0.17749942016601564,0.14970024108886718,0.14639427185058593,0.15088235473632813,0.16284671020507813,0.15991635131835938,0.17738790893554687,0.16271124267578124,0.16181309509277345,0.15764923095703126,0.13440061950683593,0.14363714599609376,0.15185345458984376,0.1655077362060547,0.15362457275390626,0.15800770568847655,0.14364266967773437,0.15316914367675782,0.149227783203125,0.15705471801757812,0.17019683837890626,0.15564544677734374,0.13893017578125,0.17221719360351562,0.12079789733886719,0.17304859924316407,0.13660791015625,0.15238720703125,0.18588272094726563,0.15011532592773438,0.16035354614257813,0.13331539916992188,0.15602084350585937,0.16965328979492186,0.17854571533203126,0.14013226318359376,0.14414825439453124,0.13457365417480469,0.16866842651367187,0.132943115234375,0.1618475341796875,0.15366177368164063,0.1606844482421875,0.15751553344726563,0.16539401245117188,0.17237664794921875,0.16179190063476562,0.13755117797851563,0.17568374633789063,0.14270440673828125,0.1677425537109375,0.1482886199951172,0.15020933532714845,0.16226036071777344,0.16508416748046875,0.1578015899658203,0.16540145874023438,0.16532241821289062,0.15055690002441408,0.1473067626953125,0.1373236083984375,0.15659486389160157,0.1637001953125,0.14654286193847657,0.13985536193847656,0.15827830505371093,0.16945535278320312,0.16121478271484374,0.14456199645996093,0.13183889770507812,0.131035400390625,0.15202816772460936,0.15190023803710936,0.1722794952392578,0.16758906555175782,0.1202945556640625,0.15979794311523438,0.162946044921875,0.14537857055664063,0.15987261962890625,0.155749755859375,0.15595204162597656,0.15202316284179687,0.15291860961914064,0.16384982299804687,0.15377218627929687,0.15997735595703125,0.16414669799804688,0.15681283569335938,0.16696585083007812,0.14489801025390625,0.14392854309082032,0.15830943298339845,0.16609381103515625,0.16718331909179687,0.1387504425048828,0.1446025390625,0.16517752075195313,0.16016290283203125,0.163563232421875,0.13915841674804688,0.17850311279296874,0.13380026245117188,0.15193724060058594,0.16315664672851563,0.14708544921875,0.16492745971679687,0.15218634033203124,0.14279100036621092,0.1487019500732422,0.15200613403320312,0.16009991455078126,0.1663622283935547,0.16392977905273437,0.15199247741699218,0.15617086791992188,0.15019766235351562,0.144365478515625,0.1530717010498047,0.1562625732421875,0.16456610107421876,0.18491032409667968,0.13791473388671874,0.15945980834960938,0.12459654235839844,0.16203494262695312,0.1592950134277344,0.20781051635742187,0.16578152465820312,0.1576424255371094,0.1552613525390625,0.14069268798828125,0.17048316955566406,0.14693183898925782,0.15960562133789064,0.15228128051757814,0.19503530883789064,0.16207023620605468,0.15289002990722655,0.15218133544921875,0.16533702087402344,0.14468597412109374,0.1687053985595703,0.1563296661376953,0.14236105346679687,0.16858743286132813]};\n",
       "\n",
       "  var data = [data0];\n",
       "  var layout = {\"title\":\"loss by time\"};\n",
       "\n",
       "  Plotly.plot('plot-634520798', data, layout);\n",
       "})();\n",
       "});\n",
       "      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plotLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict  your Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the processed test data to verify the prediction result of the model and compute the accuracy. The accuracy shall be about 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 44.94000000000001%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetAccuracyResult\u001b[39m"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getAccuracyResult(): String = {\n",
    "    def findMaxItemIndex(iNDArray: INDArray): INDArray = {\n",
    "        Nd4j.argMax(iNDArray, 1)\n",
    "    }\n",
    "    \n",
    "    def getAccuracy(score: INDArray, testExpectLabel: INDArray): Double = {\n",
    "        import org.nd4s.Implicits._\n",
    "        val scoreIndex = findMaxItemIndex(score)\n",
    "        val expectResultIndex = findMaxItemIndex(testExpectLabel)\n",
    "        val accINDArray = scoreIndex.eq(expectResultIndex)\n",
    "        (accINDArray.sumT / score.shape()(0))\n",
    "    }\n",
    "    \n",
    "    \n",
    "    val accuracyResultBuffer = scala.collection.mutable.Buffer.empty[Double]\n",
    "    val iterator = cifar10.testBatches(trainBatchSize)\n",
    "    while (iterator.hasNext) {\n",
    "        val Cifar10.Batch(testDatalabels, testDataBatch) = iterator.next()\n",
    "        val predictResult = Await.result(myNeuralNetwork(testDataBatch).predict.toScalaFuture, Duration.Inf)\n",
    "        val accuracyResult = getAccuracy(predictResult ,testDatalabels)\n",
    "        accuracyResultBuffer += accuracyResult\n",
    "    }\n",
    "\n",
    "    val accuracy = accuracyResultBuffer.sum / accuracyResultBuffer.length\n",
    "    \n",
    "    s\"${accuracy * 100.0}%\"\n",
    "}\n",
    "\n",
    "\n",
    "println(s\"The accuracy is ${getAccuracyResult()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have learned the follows in this article:\n",
    "\n",
    "* Prepare and process CIFAR10 data\n",
    "* Build a three-layers model with a convolutional layer and two full connection layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
